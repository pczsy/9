<html><head><meta charset='utf-8'><meta name='viewport' content='width=device-width, initial-scale=1'>
<meta name='applicable-device' content='pc'><meta name='keywords' content='电脑,电脑讲解,电脑技术,编程,电脑故障维修写了个爬虫代理ip的脚本给大家使用' />
<script src='../../highlight/highlight.pack.js'></script>
<link rel='stylesheet' type='text/css' href='../../highlight/styles/monokai.css'/>

<link rel='stylesheet' href='../../fenxiang/dist/css/share.min.css'>
<script src='../../fenxiang/src/js/social-share.js'></script>
<script src='../../fenxiang/src/js/qrcode.js'></script>

</head><body><script>hljs.initHighlightingOnLoad();</script><script>
var system ={};  
var p = navigator.platform;       
system.win = p.indexOf('Win') == 0;  
system.mac = p.indexOf('Mac') == 0;  
system.x11 = (p == 'X11') || (p.indexOf('Linux') == 0);     
if(system.win||system.mac||system.xll){
document.write("<link href='../css/3.css' rel='stylesheet' type='text/css'>");}else{ document.write("<link href='../css/3wap.css' rel='stylesheet' type='text/css'>");}</script><script src='../../js/3.js'></script><div class='div2'><div class='heading_nav'><ul><div><li><a href='../../index.html'>首页</a></li>
</div><div onclick='hidden1()' >分享</div>
</ul></div></div>
<div id='heading_nav2'> 
<li class='row' >
<div class='social-share' data-mode='prepend'><a href='javascript:' class='social-share-icon icon-heart'></a></div></li></div><script charset='utf-8' src='../../3/js/hengfu.js'></script><script charset='utf-8' src='../../3/js/hengfu2.js'></script><hr><div class='div1'><div class='biaoti'><center>写了个爬虫代理ip的脚本给大家使用</center></div><div class='banquan'>原文出处:本文由博客园博主小小咸鱼YwY提供。<br/>
原文连接:https://www.cnblogs.com/pythonywy/p/11278893.html</div><br>
    <h1 id="写了个爬虫代理ip的脚本给大家使用">写了个爬虫代理ip的脚本给大家使用</h1>
<h2 id="一.代码">一.代码</h2>
<pre><code><code>import requests
from lxml.html import etree


url = &#39;http://www.kuaidaili.com/free/&#39;
rp =requests.get(url)
rp_html = etree.HTML(rp.text)

#找xpath
ip_xpath = &#39;//*[@id=&quot;list&quot;]/table/tbody/tr/td[1]/text()&#39;
port_xpath = &#39;//*[@id=&quot;list&quot;]/table/tbody/tr/td[2]/text()&#39;
http_or_https_xpath =&#39;//*[@id=&quot;list&quot;]/table/tbody/tr/td[4]/text()&#39;

#匹配内容
ip_list = rp_html.xpath(ip_xpath)
port_list = rp_html.xpath(port_xpath)
http_or_https_list = rp_html.xpath(http_or_https_xpath)

#进行组合
list_zip = zip(ip_list,port_list,http_or_https_list)
proxy_dict= {}
proxy_list = []
for ip,port,http_or_https in list_zip:
    proxy_dict[http_or_https] = f&#39;{ip}:{port}&#39;
    proxy_list.append(proxy_dict)
    proxy_dict = {}
print(proxy_list)
#list就是啦,你们可以用random模块随机选一个进行后续的爬取

#一页不够嘛那我们就爬十写
#先看规则
&#39;&#39;&#39;
第一页:https://www.kuaidaili.com/free/inha/1/
第二页: https://www.kuaidaili.com/free/inha/2/
后面就不用说了吧
&#39;&#39;&#39;</code></pre>
<p><code>http://www.kuaidaili.com/free/</code>这个ip代理网站不错哈</p>

</div>
</div><hr><script charset='utf-8' src='../../js/sming.js'></script></body></html>